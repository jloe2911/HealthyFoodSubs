{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0b1b4e-1693-4f7e-8a58-d62a1f48257a",
   "metadata": {},
   "source": [
    "**------------------------------------------------------------------------------------------------------------------------------------------------------**\n",
    "\n",
    "k-fold cross-validation\n",
    "\n",
    "**Input: Knowledge Graph**\n",
    "\n",
    "**GNN-based Link Prediction Model: GraphSAGE, and GAT**\n",
    "\n",
    "**Output: \"Food\" Embeddings**\n",
    "\n",
    "**------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0c4b64-4e8b-4f55-b3c1-8259d10d0d92",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6f42059-82c8-4877-b7dd-36aeb2e5b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import torch_geometric\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv, Linear, to_hetero\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "358141ff-57c5-41a4-bfb7-27d3fb7c1cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vModel = 'GraphSAGE'\n",
    "vModel = 'GAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9edec3-f986-4ab1-8392-6abf6a60440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = 5\n",
    "n_input_feat = 10\n",
    "n_epochs = 201"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71e7c51-fcd5-442e-888a-6a8e81003c5b",
   "metadata": {},
   "source": [
    "# 1) Create HeteroGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd72927-65a5-4e67-a4e2-65246d321090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_node_csv(path, index_col, encoders=None, **kwargs):\n",
    "    df = pd.read_csv(path, index_col=index_col, **kwargs)\n",
    "    mapping = {index: i for i, index in enumerate(df.index.unique())}\n",
    "\n",
    "    x = None\n",
    "    if encoders is not None:\n",
    "        xs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        x = torch.cat(xs, dim=-1)\n",
    "\n",
    "    return x, mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c68addb-3168-473d-b0cb-3c20371ed54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_edge_csv(path, src_index_col, src_mapping, dst_index_col, dst_mapping, encoders=None, **kwargs):\n",
    "    df = pd.read_csv(path, **kwargs)\n",
    "\n",
    "    src = [src_mapping[index] for index in df[src_index_col]]\n",
    "    dst = [dst_mapping[index] for index in df[dst_index_col]]\n",
    "    edge_index = torch.tensor([src, dst])\n",
    "\n",
    "    edge_attr = None\n",
    "    if encoders is not None:\n",
    "        edge_attrs = [encoder(df[col]) for col, encoder in encoders.items()]\n",
    "        edge_attr = torch.cat(edge_attrs, dim=-1)\n",
    "\n",
    "    return edge_index, edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c836cced-d5c9-47db-81d6-59b74d343398",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, food_mapping = load_node_csv('../Input Data/data/all_foods.csv', index_col='subject')\n",
    "_, nutrient_mapping = load_node_csv('../Input Data/data/df_food_nutrient.csv', index_col='object')\n",
    "_, tag_mapping = load_node_csv('../Input Data/data/df_food_tag.csv', index_col='object')\n",
    "_, category_mapping = load_node_csv('../Input Data/data/df_food_cat.csv', index_col='object')\n",
    "_, flavor_mapping = load_node_csv('../Input Data/data/df_food_flavor.csv', index_col='object')\n",
    "_, product_mapping = load_node_csv('../Input Data/data/df_product_ingredient.csv', index_col='subject')\n",
    "_, ingredient_mapping = load_node_csv('../Input Data/data/df_product_ingredient.csv', index_col='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "098c5558-603f-4d1f-b0dd-e305d50dcd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_subs_index, _ = load_edge_csv('../Input Data/data/df_food_subs.csv', src_index_col='source_id', src_mapping=food_mapping, dst_index_col='destination_id', dst_mapping=food_mapping)\n",
    "subs_food_index, _ = load_edge_csv('../Input Data/data/df_food_subs.csv', src_index_col='destination_id', src_mapping=food_mapping, dst_index_col='source_id', dst_mapping=food_mapping)\n",
    "food_nutrient_index, _ = load_edge_csv('../Input Data/data/df_food_nutrient.csv', src_index_col='subject', src_mapping=food_mapping, dst_index_col='object', dst_mapping=nutrient_mapping)\n",
    "food_tag_index, _ = load_edge_csv('../Input Data/data/df_food_tag.csv', src_index_col='subject', src_mapping=food_mapping, dst_index_col='object', dst_mapping=tag_mapping)\n",
    "food_cat_index, _ = load_edge_csv('../Input Data/data/df_food_cat.csv', src_index_col='subject', src_mapping=food_mapping, dst_index_col='object', dst_mapping=category_mapping)\n",
    "food_flavor_index, _ = load_edge_csv('../Input Data/data/df_food_flavor.csv', src_index_col='subject', src_mapping=food_mapping, dst_index_col='object', dst_mapping=flavor_mapping)\n",
    "product_ingredient_index, _ = load_edge_csv('../Input Data/data/df_product_ingredient.csv', src_index_col='subject', src_mapping=product_mapping, dst_index_col='object', dst_mapping=ingredient_mapping)\n",
    "food_ingredient_index, _ = load_edge_csv('../Input Data/data/df_food_ingredient.csv', src_index_col='subject', src_mapping=food_mapping, dst_index_col='object', dst_mapping=ingredient_mapping)\n",
    "ingredient_food_index, _ = load_edge_csv('../Input Data/data/df_food_ingredient.csv', src_index_col='object', src_mapping=ingredient_mapping, dst_index_col='subject', dst_mapping=food_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1815804-e937-4208-bb91-0a2011fc8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "\n",
    "data['Food'].num_nodes = len(food_mapping)\n",
    "data['Nutrient'].num_nodes = len(nutrient_mapping)\n",
    "data['Category'].num_nodes = len(category_mapping)\n",
    "#data['Tag'].num_nodes = len(tag_mapping)\n",
    "#data['Flavor'].num_nodes = len(flavor_mapping)\n",
    "#data['Product'].num_nodes = len(product_mapping)\n",
    "#data['Ingredient'].num_nodes = len(ingredient_mapping)\n",
    "\n",
    "data['Food', 'isSubstitutedBy', 'Food'].edge_index = food_subs_index\n",
    "data['Food', 'substitutes', 'Food'].edge_index = subs_food_index\n",
    "data['Food', 'containsNutrient', 'Nutrient'].edge_index = food_nutrient_index\n",
    "data['Food', 'isInCategory', 'Category'].edge_index = food_cat_index\n",
    "#data['Food', 'hasTag', 'Tag'].edge_index = food_tag_index\n",
    "#data['Food', 'hasFlavor', 'Flavor'].edge_index = food_flavor_index\n",
    "#data['Product', 'containsIngredient', 'Ingredient'].edge_index = product_ingredient_index\n",
    "#data['Food', 'sameAs', 'Ingredient'].edge_index = food_ingredient_index\n",
    "#data['Ingredient', 'sameAs', 'Food'].edge_index = ingredient_food_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f7902d-ede1-4164-bc7c-0119f835b29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mFood\u001b[0m={ num_nodes=9372 },\n",
       "  \u001b[1mNutrient\u001b[0m={ num_nodes=63883 },\n",
       "  \u001b[1mCategory\u001b[0m={ num_nodes=13 },\n",
       "  \u001b[1m(Food, isSubstitutedBy, Food)\u001b[0m={ edge_index=[2, 1841] },\n",
       "  \u001b[1m(Food, substitutes, Food)\u001b[0m={ edge_index=[2, 1841] },\n",
       "  \u001b[1m(Food, containsNutrient, Nutrient)\u001b[0m={ edge_index=[2, 300523] },\n",
       "  \u001b[1m(Food, isInCategory, Category)\u001b[0m={ edge_index=[2, 1667] }\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e88f6-ad87-480f-87aa-a6b34c7f370b",
   "metadata": {},
   "source": [
    "# 2) Run Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10ac04f-9b8c-4ce5-b7e7-ee46e909d4e0",
   "metadata": {},
   "source": [
    "**GraphSAGE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f9b3679-db64-47f4-81b5-5517f7bfea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGEEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3965ac-1070-415f-9344-2d9c87b7a389",
   "metadata": {},
   "source": [
    "**GAT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef1251f7-10c9-44a1-865c-ff2442342006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv((-1, -1), hidden_channels, add_self_loops=False)\n",
    "        self.lin1 = Linear(n_input_feat, hidden_channels)\n",
    "        self.conv2 = GATConv((-1, -1), out_channels, add_self_loops=False)\n",
    "        self.lin2 = Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index) + self.lin1(x)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index) + self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c32bc0-5625-46ab-9b99-b45b766e1af5",
   "metadata": {},
   "source": [
    "**------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb875e3d-ebb5-4250-8985-d85bb16269b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        if vModel == 'GraphSAGE':\n",
    "            self.encoder = GraphSAGEEncoder(hidden_channels, hidden_channels)\n",
    "        elif vModel == 'GAT': \n",
    "            self.encoder = GATEncoder(hidden_channels, hidden_channels)\n",
    "        else:\n",
    "            'No Model is chosen !'\n",
    "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return z_dict, self.decoder(z_dict, edge_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71db9edc-b95e-4927-8e8c-5b18f7e82597",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['Food'][row], z_dict['Food'][col]], dim=-1)\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd86547c-d5d7-48a8-9302-6257f2c800de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(pred, target):\n",
    "    return (pred - target.to(pred.dtype)).pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392c5d6-7a04-45e8-b9cc-99c919ea3e16",
   "metadata": {},
   "source": [
    "**------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfec233-4e43-474f-b09f-7161336e7ee8",
   "metadata": {},
   "source": [
    "**Add random Node Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c7e8ec-90f9-43ce-9564-ba5369e74699",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types, edge_types = data.metadata()\n",
    "for node in node_types: \n",
    "    data[node].x = torch.rand(data[node].num_nodes, n_input_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9803f06-5595-4d85-b1dd-674380c2fe1a",
   "metadata": {},
   "source": [
    "**------------------------------------------------------------------------------------------------------------------------------------------------------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e8daaa-f4f3-4f70-8aae-74d78ff35b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data):    \n",
    "    print('------------------------------------------------------------------')\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        #forward\n",
    "        h, pred = model(data.x_dict, data.edge_index_dict, data['Food', 'isSubstitutedBy', 'Food'].edge_index)\n",
    "        target = data['Food', 'isSubstitutedBy', 'Food'].edge_label\n",
    "\n",
    "        #loss\n",
    "        loss = mse_loss(pred, target)\n",
    "\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, _, train_rmse = eval_model(data)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "936b7c0d-da38-42c6-8e1c-3525c3625c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_model(data):\n",
    "    model.eval()\n",
    "    h, pred = model(data.x_dict, data.edge_index_dict, data['Food', 'isSubstitutedBy', 'Food'].edge_index)\n",
    "    pred = pred.clamp(min=0, max=1)\n",
    "    target = data['Food', 'isSubstitutedBy', 'Food'].edge_label.float()\n",
    "    rmse = F.mse_loss(pred, target).sqrt()\n",
    "    return h, pred, float(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36419e60-8a05-4a4f-9909-759ac662be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_foods(data, i):\n",
    "    test_u = data['Food', 'isSubstitutedBy', 'Food']['edge_label_index'][0]\n",
    "\n",
    "    reverse_food_mapping = dict(zip(food_mapping.values(),food_mapping.keys()))\n",
    "    reverse_test_u = []\n",
    "\n",
    "    for u in test_u:\n",
    "        reverse_test_u.append(reverse_food_mapping[u.item()])\n",
    "\n",
    "    foods_2_test = pd.DataFrame()\n",
    "    foods_2_test['id'] = reverse_test_u\n",
    "    foods_2_test.to_csv(f'../Output/k_fold_5/{vModel}_{i}_foods_2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26723a0d-5152-4207-8c34-b31db657fecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "Epoch: 000, Loss: 0.7364, Train: 0.2310\n",
      "Epoch: 010, Loss: 0.0389, Train: 0.0099\n",
      "Epoch: 020, Loss: 0.0052, Train: 0.0328\n",
      "Epoch: 030, Loss: 0.0091, Train: 0.0798\n",
      "Epoch: 040, Loss: 0.0042, Train: 0.0669\n",
      "Epoch: 050, Loss: 0.0030, Train: 0.0432\n",
      "Epoch: 060, Loss: 0.0028, Train: 0.0337\n",
      "Epoch: 070, Loss: 0.0023, Train: 0.0311\n",
      "Epoch: 080, Loss: 0.0020, Train: 0.0302\n",
      "Epoch: 090, Loss: 0.0017, Train: 0.0294\n",
      "Epoch: 100, Loss: 0.0015, Train: 0.0284\n",
      "Epoch: 110, Loss: 0.0013, Train: 0.0270\n",
      "Epoch: 120, Loss: 0.0011, Train: 0.0246\n",
      "Epoch: 130, Loss: 0.0010, Train: 0.0231\n",
      "Epoch: 140, Loss: 0.0009, Train: 0.0223\n",
      "Epoch: 150, Loss: 0.0008, Train: 0.0210\n",
      "Epoch: 160, Loss: 0.0008, Train: 0.0200\n",
      "Epoch: 170, Loss: 0.0007, Train: 0.0189\n",
      "Epoch: 180, Loss: 0.0006, Train: 0.0182\n",
      "Epoch: 190, Loss: 0.0006, Train: 0.0173\n",
      "Epoch: 200, Loss: 0.0005, Train: 0.0165\n",
      "------------------------------------------------------------------\n",
      "Epoch: 000, Loss: 1.6167, Train: 0.2730\n",
      "Epoch: 010, Loss: 0.0232, Train: 0.0495\n",
      "Epoch: 020, Loss: 0.0787, Train: 0.2641\n",
      "Epoch: 030, Loss: 0.0132, Train: 0.0437\n",
      "Epoch: 040, Loss: 0.0059, Train: 0.0225\n",
      "Epoch: 050, Loss: 0.0068, Train: 0.0693\n",
      "Epoch: 060, Loss: 0.0034, Train: 0.0559\n",
      "Epoch: 070, Loss: 0.0035, Train: 0.0346\n",
      "Epoch: 080, Loss: 0.0030, Train: 0.0330\n",
      "Epoch: 090, Loss: 0.0027, Train: 0.0365\n",
      "Epoch: 100, Loss: 0.0026, Train: 0.0376\n",
      "Epoch: 110, Loss: 0.0024, Train: 0.0362\n",
      "Epoch: 120, Loss: 0.0022, Train: 0.0343\n",
      "Epoch: 130, Loss: 0.0021, Train: 0.0327\n",
      "Epoch: 140, Loss: 0.0020, Train: 0.0314\n",
      "Epoch: 150, Loss: 0.0018, Train: 0.0304\n",
      "Epoch: 160, Loss: 0.0017, Train: 0.0295\n",
      "Epoch: 170, Loss: 0.0016, Train: 0.0286\n",
      "Epoch: 180, Loss: 0.0016, Train: 0.0278\n",
      "Epoch: 190, Loss: 0.0015, Train: 0.0270\n",
      "Epoch: 200, Loss: 0.0014, Train: 0.0263\n",
      "------------------------------------------------------------------\n",
      "Epoch: 000, Loss: 1.6596, Train: 0.4458\n",
      "Epoch: 010, Loss: 0.1177, Train: 0.0565\n",
      "Epoch: 020, Loss: 0.0121, Train: 0.0491\n",
      "Epoch: 030, Loss: 0.0168, Train: 0.0945\n",
      "Epoch: 040, Loss: 0.0110, Train: 0.0989\n",
      "Epoch: 050, Loss: 0.0057, Train: 0.0739\n",
      "Epoch: 060, Loss: 0.0047, Train: 0.0566\n",
      "Epoch: 070, Loss: 0.0042, Train: 0.0482\n",
      "Epoch: 080, Loss: 0.0037, Train: 0.0442\n",
      "Epoch: 090, Loss: 0.0032, Train: 0.0417\n",
      "Epoch: 100, Loss: 0.0029, Train: 0.0396\n",
      "Epoch: 110, Loss: 0.0025, Train: 0.0375\n",
      "Epoch: 120, Loss: 0.0023, Train: 0.0355\n",
      "Epoch: 130, Loss: 0.0021, Train: 0.0334\n",
      "Epoch: 140, Loss: 0.0019, Train: 0.0315\n",
      "Epoch: 150, Loss: 0.0017, Train: 0.0299\n",
      "Epoch: 160, Loss: 0.0015, Train: 0.0285\n",
      "Epoch: 170, Loss: 0.0014, Train: 0.0273\n",
      "Epoch: 180, Loss: 0.0013, Train: 0.0260\n",
      "Epoch: 190, Loss: 0.0012, Train: 0.0249\n",
      "Epoch: 200, Loss: 0.0011, Train: 0.0238\n",
      "------------------------------------------------------------------\n",
      "Epoch: 000, Loss: 0.7677, Train: 0.1816\n",
      "Epoch: 010, Loss: 0.0106, Train: 0.0000\n",
      "Epoch: 020, Loss: 0.0312, Train: 0.1226\n",
      "Epoch: 030, Loss: 0.0063, Train: 0.1040\n",
      "Epoch: 040, Loss: 0.0075, Train: 0.0206\n",
      "Epoch: 050, Loss: 0.0028, Train: 0.0261\n",
      "Epoch: 060, Loss: 0.0030, Train: 0.0443\n",
      "Epoch: 070, Loss: 0.0024, Train: 0.0431\n",
      "Epoch: 080, Loss: 0.0021, Train: 0.0355\n",
      "Epoch: 090, Loss: 0.0019, Train: 0.0311\n",
      "Epoch: 100, Loss: 0.0017, Train: 0.0293\n",
      "Epoch: 110, Loss: 0.0016, Train: 0.0284\n",
      "Epoch: 120, Loss: 0.0014, Train: 0.0275\n",
      "Epoch: 130, Loss: 0.0013, Train: 0.0266\n",
      "Epoch: 140, Loss: 0.0012, Train: 0.0256\n",
      "Epoch: 150, Loss: 0.0011, Train: 0.0247\n",
      "Epoch: 160, Loss: 0.0010, Train: 0.0239\n",
      "Epoch: 170, Loss: 0.0010, Train: 0.0230\n",
      "Epoch: 180, Loss: 0.0009, Train: 0.0226\n",
      "Epoch: 190, Loss: 0.0008, Train: 0.0206\n",
      "Epoch: 200, Loss: 0.0007, Train: 0.0200\n",
      "------------------------------------------------------------------\n",
      "Epoch: 000, Loss: 0.9070, Train: 0.4977\n",
      "Epoch: 010, Loss: 0.0569, Train: 0.0316\n",
      "Epoch: 020, Loss: 0.0175, Train: 0.0169\n",
      "Epoch: 030, Loss: 0.0050, Train: 0.0192\n",
      "Epoch: 040, Loss: 0.0024, Train: 0.0263\n",
      "Epoch: 050, Loss: 0.0020, Train: 0.0291\n",
      "Epoch: 060, Loss: 0.0017, Train: 0.0289\n",
      "Epoch: 070, Loss: 0.0014, Train: 0.0272\n",
      "Epoch: 080, Loss: 0.0012, Train: 0.0252\n",
      "Epoch: 090, Loss: 0.0011, Train: 0.0234\n",
      "Epoch: 100, Loss: 0.0010, Train: 0.0221\n",
      "Epoch: 110, Loss: 0.0008, Train: 0.0211\n",
      "Epoch: 120, Loss: 0.0007, Train: 0.0201\n",
      "Epoch: 130, Loss: 0.0006, Train: 0.0188\n",
      "Epoch: 140, Loss: 0.0006, Train: 0.0173\n",
      "Epoch: 150, Loss: 0.0005, Train: 0.0161\n",
      "Epoch: 160, Loss: 0.0004, Train: 0.0150\n",
      "Epoch: 170, Loss: 0.0004, Train: 0.0139\n",
      "Epoch: 180, Loss: 0.0003, Train: 0.0129\n",
      "Epoch: 190, Loss: 0.0003, Train: 0.0119\n",
      "Epoch: 200, Loss: 0.0002, Train: 0.0110\n"
     ]
    }
   ],
   "source": [
    "for i in range(k_fold):    \n",
    "    \n",
    "    #Split into Train, Test, Val Sets\n",
    "    train_data, val_data, test_data = T.RandomLinkSplit(\n",
    "        num_val=0.1,\n",
    "        num_test=0.1,\n",
    "        neg_sampling_ratio=0,\n",
    "        edge_types=[('Food', 'isSubstitutedBy', 'Food')],\n",
    "        rev_edge_types=[('Food', 'substitutes', 'Food')],\n",
    "    )(data)\n",
    "\n",
    "    #Initialize Model\n",
    "    model = Model(hidden_channels=32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    train_data['Food', 'isSubstitutedBy', 'Food'].edge_label = torch.ones(train_data['Food', 'isSubstitutedBy', 'Food'].num_edges)\n",
    "    test_data['Food', 'isSubstitutedBy', 'Food'].edge_label = torch.ones(test_data['Food', 'isSubstitutedBy', 'Food'].num_edges)\n",
    "    val_data['Food', 'isSubstitutedBy', 'Food'].edge_label = torch.ones(val_data['Food', 'isSubstitutedBy', 'Food'].num_edges)\n",
    "    \n",
    "    #Train Model\n",
    "    train(train_data)\n",
    "\n",
    "    #Remember the Foods that are contained in the Test Set\n",
    "    get_test_foods(test_data, i)\n",
    "    \n",
    "    #Get Embeddings from the Test Foods\n",
    "    with torch.no_grad():\n",
    "        h, pred, rmse = eval_model(test_data)\n",
    "\n",
    "    foods = food_mapping.keys()\n",
    "    food_embeddings = dict(zip(foods, h['Food']))\n",
    "    \n",
    "    for j in range(2):\n",
    "        fw = open(f'../Output/k_fold_5/{vModel}_{i}_food_embeddings.txt','w')\n",
    "        fw.write(str(len(foods))+' '+str(len(h['Food'][0]))+'\\n')\n",
    "        for food in foods:\n",
    "            fw.write(food+' ')\n",
    "            for i in range(len(h['Food'][0])):\n",
    "                value = str(food_embeddings[food][i].item()).strip()\n",
    "                fw.write(value+' ')\n",
    "            fw.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
